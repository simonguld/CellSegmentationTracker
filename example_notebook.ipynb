{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code, it will be demonstrated how to use CellSegmentationTracker and its methods. As sample data, the epi500 image sample in the resources folder will be used. In this folder, you can also find the xml file generated by running the segmentation and tracking as well as the spots, tracks and edges csv files generated by CellSegmentationTracker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from cellsegmentationtracker import CellSegmentationTracker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we will walk through the class parameters one by one and finally initialize an instance of CellSegmentationTracker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Change directory to current one\n",
    "dir_path = os.path.dirname(os.path.realpath(__file__))\n",
    "os.chdir(dir_path)\n",
    "\n",
    "# Set paths to executables. If you want to do segmentation and tracking, you need to provide paths to ImageJ and Cellpose. \n",
    "# If you already have an xml file and just want to use CellSegmentationTracker to generate csv files, \n",
    "# calculate velocities or analyse the results, you don't have to provide these\n",
    "cellpose_python_filepath = 'C:\\\\Users\\\\Simon Andersen\\\\miniconda3\\\\envs\\\\cellpose\\\\python.exe'\n",
    "imj_path = \"C:\\\\Users\\\\Simon Andersen\\\\Fiji.app\\\\ImageJ-win64.exe\"\n",
    "\n",
    "# Set path to .tif image file (or folder with images). If you already have an xml file, you don't have to provide it\n",
    "image_path = os.path.join(dir_path, 'resources', 'epi500_sample_images.tif')\n",
    "\n",
    "# If you have already done segmentation and tracking, you can simply provide the path to the xml file.\n",
    "xml_path = None  #os.path.join(dir_path, 'resources', 'epi500_sample_images.xml')\n",
    "\n",
    "\n",
    "# Set path to output folder. If None, results will be outputted in the same folder as the image.\n",
    "output_folder_path = os.path.join(dir_path, 'resources')\n",
    "\n",
    "# Set whether to use the pretrained model or not. If not, you need to provide a path to a custom model\n",
    "use_model = 'EPI500'\n",
    "custom_model_path = None\n",
    "\n",
    "# Set whether to open ImageJ and show the segmentation and tracking results\n",
    "show_segmentation = True\n",
    "\n",
    "# Set cellpose and trackmate settings. If you don't provide any, the default settings will be used\n",
    "cellpose_dict = {\n",
    "            'TARGET_CHANNEL' : 0,\n",
    "            'OPTIONAL_CHANNEL_2': 0,\n",
    "            'FLOW_THRESHOLD': 0.4,\n",
    "            'CELLPROB_THRESHOLD': 0.5,\n",
    "            'CELL_DIAMETER': 0.0, # If 0.0, the diameter will be estimated by Cellpose\n",
    "            'USE_GPU': False,\n",
    "            'SIMPLIFY_CONTOURS': True\n",
    "            }\n",
    "# Beware that if you set ALLOW_TRACK_SPLITTING and/or ALLOW_TRACK_MERGING to True, the calculated velocities might be incorrect, as several \n",
    "# cells will be merged into one track and can be present at the same time\n",
    "trackmate_dict = {'LINKING_MAX_DISTANCE': 15.0,\n",
    "                                         'GAP_CLOSING_MAX_DISTANCE': 15.0,\n",
    "                                         'MAX_FRAME_GAP': 2,\n",
    "                                         'ALLOW_TRACK_SPLITTING': False, \n",
    "                                         'ALLOW_TRACK_MERGING': False,\n",
    "             }\n",
    "\n",
    "\n",
    "# Now having set all parameters, we are ready to initialise the CellSegmentationTracker object\n",
    "cst = CellSegmentationTracker(imagej_filepath = imj_path, cellpose_python_filepath = cellpose_python_filepath, \\\n",
    "                              image_folder_path = image_path, xml_path = xml_path, output_folder_path = output_folder_path,\n",
    "                  use_model = use_model, custom_model_path = custom_model_path, show_segmentation = show_segmentation, cellpose_dict = dict(), trackmate_dict = dict(),)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run the segmentation and tracking, simply call the run_segmentation_tracking() method\n",
    "cst.run_segmentation_tracking()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After the segmentation and tracking is done, you can generate csv files with the results by calling the generate_csv_files() method\n",
    "\n",
    "# Spot features will be extracted automatically. Decide whether to calculate cell velocities, as well as track and edge features. By default, everything is extracted and saved\n",
    "calculate_velocities = True\n",
    "get_tracks = True\n",
    "get_edges = True\n",
    "\n",
    "# If you want to save the csv files, set save_csv_files to True and provide a name for the csv files. If None, the name will be the same as the image name.\n",
    "# The file(s) will be saved in the output folder if provided, otherwise in the same folder as the image if provided, otherwise in the current working directory\n",
    "cst.generate_csv_files(calculate_velocities = calculate_velocities, get_tracks = get_tracks, get_edges = get_edges, save_csv_files = True, name = None)\n",
    "\n",
    "# Now, you can access the spots, tracks and edges dataframes as follows:\n",
    "# The final two columns of the spots object are the velocities (if calculated) in the x and y direction, respectively\n",
    "df_spots, df_tracks, df_edges = cst.df_spots, cst.df_tracks, cst.df_edges\n",
    "\n",
    "df_spots.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get basic settings and information about the segmentation and tracking, you can call the print_settings() method\n",
    "cst.print_settings()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cellpose",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
